[project]
name = "lumina-backend"
version = "0.1.0"
description = "AI-powered consulting tool backend"
authors = [
    { name = "CreasyBear", email = "unknown@domain.invalid" }
]
dependencies = [
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.30.6",
    "sqlalchemy>=2.0.35",
    "psycopg2-binary>=2.9.9",
    "pydantic>=2.9.2",
    "python-jose[cryptography]>=3.3.0",
    "passlib[bcrypt]>=1.7.4",
    "alembic>=1.13.2",
    "requests>=2.32.3",
    "openai>=0.27.0",
    "pytest>=8.3.3",
    "pytest-asyncio>=0.23.7,<0.24.0",  # Adjusted to satisfy llama-deploy
    "httpx>=0.27.2",
    "pydantic-settings>=2.5.2",
    "llama-index-llms-openai>=0.2.9",
    "llama-index-embeddings-openai>=0.2.5",
    "llama-index-readers-file>=0.2.2",
    "llama-index-utils-workflow>=0.2.1",
    "llama-index-experimental>=0.3.3",
    "pandas>=2.2.3",
    "sqlalchemy-utils>=0.41.2",
    "llama-index-callbacks-arize-phoenix>=0.2.1",
    "llama-deploy>=0.1.3",
]
readme = "README.md"
requires-python = ">= 3.8"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.rye]
managed = true

dev-dependencies = []

[tool.rye.dependencies]
llama-index = "0.11.10"
pytest-asyncio = ">=0.23.7,<0.24.0"  # Adjusted to satisfy llama-deploy
llama-index-core = "0.11.10"
numpy = "1.23.5"